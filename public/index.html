<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="stylesheet" type="text/css" href="/prism.css" />

    <title>cesarFuhr.dev</title>
    <link rel="icon" href="/images/cesar_gopher.ico">
  </head>

  <body>
    <a id="top"></a>
    <nav class="navbar-wrapper">
      <ul class="navbar" id="navbar">
        <li class="navbar-header">
          <div class="navbar-brand">
            <a class="nav-link" href="/">
              <img src="/images/cesar_gopher.png" id="gopher"/>
            </a>
            <a class="nav-link" href="/">cesarfuhr.dev</a>
          </div>
          <a class="nav-icon" href="javascript:void(0)" onclick="dropMenu()">||</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/archive.html">Archive</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/about.html">About</a>
        </li>
        <!--- <li class="nav-item">
          <a class="nav-link" href="cesarfuhr.rss">RSS</a>
          </li> --->
      </ul>
    </nav>

    <main>

      <header>
        <a id="title"></a>
        <p class="date">January 26th, 2022</p>
        <h1>Distributed rate limiting in Go</h1>
        <h4 class="subtitle">The token bucket pattern implementation with a single source of truth.</h4>
      </header>

      <section class="text">
        <p>In the distributed system era some problems get a whole new perspective. One of this common problems is the denial of service by excessive calls. We always think about how this can affect our systems, but what if we were the bad actors?</p>

        <p>This blog post covers a token bucket implementation that is a simple, but effective, pattern to avoid overwhelming the services you depend on. I will focus on a client implementation, but the concept can be used to limit incoming calls and protect your service resources also.</p>

        <a id="the-token-bucket" href="#the-token-bucket">
          <h2>The token bucket</h2>
        </a>

        <img src="/images/token_bucket.svg" id="token_bucket"/>

        <p>This pattern focuses on limiting a resource rate of consumption by giving a number of tokens periodically and rejecting any token requisition when the bucket is empty. This rate limiting method is able to impose a periodic limit, but cannot shape or throttle the traffic. If a high number of token requisitions arrives in a full bucket it will authorize every one of them until there are no more tokens in it, creating a burst behavior.</p>
        <img src="/images/token_bucket_timeframe.svg" id="token_bucket_timeframe"/>

        <p>Every time the bucket is refilled, it's capacity is available for use. This method does not carry state between refills, so if in a previous cycle tokens were not used they are "thrown away" and will not be available after refiling.</p>

        <p></p>

        <p>A single instance implementation is quite simple (see the example below), since all the needed state is stored in the shared memory.</p>

        <pre><code class="language-go">// main.go
package main

import (
  "context"
  "errors"
  "fmt"
  "sync"
  "time"
)

func main() {
  action := func(context.Context) (string, error) {
    return "done", nil
  }

  ctx, cancel := context.WithTimeout(context.Background(), time.Second*3)
  defer cancel()

  // Limiting action for 2 calls every second.
  limited := limit(ctx, 2, time.Second, action)

  // Launching 5 go routines every second.
  // We should see 2 successes and 3 errors every second.
  start := time.Now()
  for {
    select {
    case <-ctx.Done():
      return
    default:
      for i := 0; i < 5; i++ {
        go func() {
          result, err := limited(ctx)
          since := time.Since(start).Milliseconds()
          fmt.Printf("%vms\t-> result: %v\t\t| error: %v\n", since, result, err)
        }()
      }
      time.Sleep(time.Second)
    }
  }
}

type actionFunc func(context.Context) (string, error)

// limit wraps a function and limits its calls over time respecting the
// max and refill period rate.
func limit(ctx context.Context, maxCalls int, refillPeriod time.Duration, action actionFunc) func(context.Context) (string, error) {
  // Start with a filled bucket.
  tokens := maxCalls
  // Creates a ticker to receive periodic events.
  ticker := time.NewTicker(refillPeriod)

  // We could use other synchronization mechanisms, but to keep it simple
  // lets use a mutex to avoid race conditions.
  var mx sync.Mutex
  go func() {
    // Defering the Stop call to make sure we don't leak the ticker.
    defer ticker.Stop()

    for {
      select {
      case <-ticker.C:
        // On every tick fill the token bucket.
        mx.Lock()
        fmt.Println("\t-> TokenBucket: refilling!!")
        tokens = maxCalls
        mx.Unlock()
      case <-ctx.Done():
        // If the context is cancelled, we should return from the
        // function and avoid leaking the go routine.
        return
      }
    }
  }()

  // requestToken request a token from the bucket and
  // if returns an error if there are no tokens available.
  requestToken := func() error {
    mx.Lock()
    defer mx.Unlock()

    if tokens <= 0 {
      return errors.New("no tokens available")
    }

    // If there are tokens available,
    // removes one from the bucket and returns nil.
    tokens--
    return nil
  }

  return func(c context.Context) (string, error) {
    if err := requestToken(); err != nil {
      return "", err
    }

    return action(ctx)
  }
}

// Output: (something like this...)
// 0ms     -> result: done         | error: <nil>
// 0ms     -> result:              | error: no tokens available
// 0ms     -> result: done         | error: <nil>
// 0ms     -> result:              | error: no tokens available
// 0ms     -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!
// 1000ms  -> result: done         | error: <nil>
// 1000ms  -> result: done         | error: <nil>
// 1000ms  -> result:              | error: no tokens available
// 1000ms  -> result:              | error: no tokens available
// 1000ms  -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!
// 2000ms  -> result: done         | error: <nil>
// 2000ms  -> result: done         | error: <nil>
// 2000ms  -> result:              | error: no tokens available
// 2000ms  -> result:              | error: no tokens available
// 2000ms  -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!</code></pre>

        <p>What if, like most of the systems being developed now-a-days, we could not rely on sharing memory (therefore having more than one instance) to build our solution?</p>

        <p>If we used a simple token bucket like the one in the example, we would need to control every running instance and make sure they respect their share of the quota. In a situation were the load increases and we need more service replicas, we would have to code a way of broadcasting the updated call limit to every instance to avoid restarting services. Even if we achieved this goal, we would still have to build a central controller to broadcast this information to the replicas.</p>

        <p>One way of doing it (and the one we will focus in this blog post) is use a database to persist and centralize the token buckets state.</p>

        <a id="a-centralized-token-bucket" href="#a-centralized-token-bucket">
          <h2>A centralized token bucket</h2>
        </a>

        <p>The first thing we need to do is create the data model for the token bucket. This model should also consider how the refill bucket action will take place.</p>

        <p>There are some alternatives to implement the bucket refill action. The more straight forward one would be creating a scheduled procedure, that runs periodically, for every bucket and simply writing its capacity to the available tokens field. Another, and more powerful, idea would be registering every requested token and using a moving time window to calculate if there are available tokens (this could even be used for throttling eventually). Both methods can lead to a functional token bucket implementation, but the first has a big cost (since every bucket would have its own scheduled task) and the second can be quite complex (and would force us to store every call to the limited resource in the database).</p>

        <p>A third way, which is a combination of the first and second, is how we will implement the pattern. Instead of creating a scheduled procedure we could, in every token requisition, calculate if we should refill the bucket or not before actually removing a token from the bucket. This can be achieved by storing the last time we refilled the bucket and its refill period, then in every token request calculate if it is time to refill.</p>

        <p>With the refill process defined, we can work on the data model. We already know we need to store the number of available tokens, the token capacity of the bucket and the last time it was refilled. To make it easier to use we also should store a bucket ID and its creation date and time. I will use SQL to describe the data model, since it is so ubiquitous.</p>

        <pre><code class="language-sql">
CREATE TABLE token_buckets (
  id            CHAR(36) PRIMARY KEY,
  available     INT UNSIGNED,
  capacity      INT UNSIGNED,
  refil_seconds INT UNSIGNED,
  last_refil_at TIMESTAMP(3)
)</code></pre>

      </section>

      <footer>
        <a href="/blog/simple-rules-to-avoid-some-range-for-loop-pitfalls.html">prev</a>
        <a href="#top">top</a>
      </footer>
    </main>

    <script src="/js/dropMenu.js"  type="text/javascript"></script>
    <script src="/js/prism.js"     type="text/javascript"></script>
  </body>
</html>
