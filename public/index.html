<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="stylesheet" type="text/css" href="/prism.css" />

    <title>cesarFuhr.dev</title>
    <link rel="icon" href="/images/cesar_gopher.ico">
  </head>

  <body>
    <a id="top"></a>
    <nav class="navbar-wrapper">
      <ul class="navbar" id="navbar">
        <li class="navbar-header">
          <div class="navbar-brand">
            <a class="nav-link" href="/">
              <img src="/images/cesar_gopher.png" id="gopher"/>
            </a>
            <a class="nav-link" href="/">cesarfuhr.dev</a>
          </div>
          <a class="nav-icon" href="javascript:void(0)" onclick="dropMenu()">||</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/archive.html">Archive</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/about.html">About</a>
        </li>
        <!--- <li class="nav-item">
          <a class="nav-link" href="cesarfuhr.rss">RSS</a>
          </li> --->
      </ul>
    </nav>

    <main>

      <header>
        <a id="title"></a>
        <p class="date">January 26th, 2022</p>
        <h1>Distributed rate limiting in Go</h1>
        <h4 class="subtitle">The token bucket pattern implementation with a single source of truth.</h4>
      </header>

      <section class="text">
        <p>In the distributed system era some problems get a whole new perspective. One of this common problems is the denial of service by excessive calls. We always think about how this can affect our systems, but what if we were the bad actors?</p>

        <p>This blog post covers a token bucket implementation that is a simple, but effective, pattern to avoid overwhelming the services you depend on. I will focus on a client implementation, but the concept can be used to limit incoming calls.</p>

        <h2>The token bucket</h2>

        <img src="/images/token_bucket.svg" id="token_bucket"/>

        <p>This pattern focuses on limiting a resource rate of consumption by giving a number of tokens periodically and rejecting any token requisition when the bucket is empty. This rate limiting method is able to impose a periodic limit, but cannot shape or throttle the traffic. If a high number of token requisitions arrives in a full bucket it will authorize every one of them until there are no more tokens in it, creating a burst behavior.</p>
        <p>A single instance implementation is quite simple (see the example below), since all the needed state is stored in the shared memory.</p>

        <pre><code class="language-go">// main.go
package main

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"time"
)

func main() {
	action := func(context.Context) (string, error) {
		return "done", nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), time.Second*3)
	defer cancel()

	// Limiting action for 2 calls every second.
	limited := limit(ctx, 2, time.Second, action)

	// Launching 5 go routines every second.
	// We should see 2 successes and 3 errors every second.
	start := time.Now()
	for {
		select {
		case <-ctx.Done():
			return
		default:
			for i := 0; i < 5; i++ {
				go func() {
					result, err := limited(ctx)
					since := time.Since(start).Milliseconds()
					fmt.Printf("%vms\t-> result: %v\t\t| error: %v\n", since, result, err)
				}()
			}
			time.Sleep(time.Second)
		}
	}
}

type actionFunc func(context.Context) (string, error)

// limit wraps a function and limits its calls over time respecting the
// max and refill period rate.
func limit(ctx context.Context, maxCalls int, refillPeriod time.Duration, action actionFunc) func(context.Context) (string, error) {
	// Start with a filled bucket.
	tokens := maxCalls
	// Creates a ticker to receive periodic events.
	ticker := time.NewTicker(refillPeriod)

	// We could use other synchronization mechanisms, but to keep it simple
	// lets use a mutex to avoid race conditions.
	var mx sync.Mutex
	go func() {
		// Defering the Stop call to make sure we don't leak the ticker.
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				// On every tick fill the token bucket.
				mx.Lock()
				fmt.Println("\t-> TokenBucket: refilling!!")
				tokens = maxCalls
				mx.Unlock()
			case <-ctx.Done():
				// If the context is cancelled, we should return from the
				// function and avoid leaking the go routine.
				return
			}
		}
	}()

	// requestToken request a token from the bucket and
	// if returns an error if there are no tokens available.
	requestToken := func() error {
		mx.Lock()
		defer mx.Unlock()

		if tokens <= 0 {
			return errors.New("no tokens available")
		}

		// If there are tokens available,
		// removes one from the bucket and returns nil.
		tokens--
		return nil
	}

	return func(c context.Context) (string, error) {
		if err := requestToken(); err != nil {
			return "", err
		}

		return action(ctx)
	}
}

// Output: (something like this...)
// 0ms     -> result: done         | error: <nil>
// 0ms     -> result:              | error: no tokens available
// 0ms     -> result: done         | error: <nil>
// 0ms     -> result:              | error: no tokens available
// 0ms     -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!
// 1000ms  -> result: done         | error: <nil>
// 1000ms  -> result: done         | error: <nil>
// 1000ms  -> result:              | error: no tokens available
// 1000ms  -> result:              | error: no tokens available
// 1000ms  -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!
// 2000ms  -> result: done         | error: <nil>
// 2000ms  -> result: done         | error: <nil>
// 2000ms  -> result:              | error: no tokens available
// 2000ms  -> result:              | error: no tokens available
// 2000ms  -> result:              | error: no tokens available
//         -> TokenBucket: refilling!!</code></pre>
        
        <p>What if, like most of the systems being developed now-a-days, we could not rely on having only one instance?</p>

        <p>If we used a simple token bucket like the one in the example we would need to control every running instance and make sure they respect their share of the quota. In a situation were the load increases and we need more service replicas, we would have to code a way of broadcasting the updated call limit to every instance to avoid restarting services.</p>


      </section>

      <footer>
        <a href="/blog/simple-rules-to-avoid-some-range-for-loop-pitfalls.html">prev</a>
        <a href="#top">top</a>
      </footer>
    </main>

    <script src="/js/dropMenu.js"  type="text/javascript"></script>
    <script src="/js/prism.js"     type="text/javascript"></script>
  </body>
</html>
